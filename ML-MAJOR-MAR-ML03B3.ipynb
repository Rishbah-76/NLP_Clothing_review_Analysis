{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:\n",
    "\n",
    "1.Describe the data\n",
    " \n",
    " a.Descriptive statistics, data type, etc.\n",
    "\n",
    "2.Analyze the text comment/ review and share the findings\n",
    "  \n",
    "  Convert the ratings into 2 classes\n",
    "   \n",
    "   a.Class: Bad when Rating <=3\n",
    "   \n",
    "   b.Class: Good otherwise\n",
    "\n",
    "3.Develop a model to predict the Rating class (created above)\n",
    "  Focus on steps to build a model\n",
    "\n",
    "4.Which algorithm can be used and why\n",
    "  Share the findings of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing all the essential modules:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import os\n",
    "from os import path\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from subprocess import check_output\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from gensim.models import word2vec\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as mt\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_profiling\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing datafile \n",
    "df = pd.read_csv(\"Womens_Clothing_E_Commerce_Reviews.csv\")\n",
    "df=df.drop(['Unnamed: 0'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Clothing ID', 'Age', 'Title', 'Review Text', 'Rating',\n",
       "       'Recommended IND', 'Positive Feedback Count', 'Division Name',\n",
       "       'Department Name', 'Class Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking all columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing ID                 int64\n",
       "Age                         int64\n",
       "Title                      object\n",
       "Review Text                object\n",
       "Rating                      int64\n",
       "Recommended IND             int64\n",
       "Positive Feedback Count     int64\n",
       "Division Name              object\n",
       "Department Name            object\n",
       "Class Name                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing datatpes of whole dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values: 2966\n",
      "Dataframe Dimension: 22628 Rows, 9 Columns\n"
     ]
    }
   ],
   "source": [
    "# dropping unnecesary columns \n",
    "df.drop(df.columns[0],inplace=True,axis=1)\n",
    "\n",
    "# Delete missing observations for following variables\n",
    "for x in [\"Division Name\",\"Department Name\",\"Class Name\",\"Review Text\"]:\n",
    "    df = df[df[x].notnull()]\n",
    "    \n",
    "# Extracting Missing Count and Unique Count by Column\n",
    "unique_count = []\n",
    "for x in df.columns:\n",
    "    unique_count.append([x,len(df[x].unique()),df[x].isnull().sum()])\n",
    "\n",
    "print(\"Missing Values: {}\".format(df.isnull().sum().sum())) #missing values\n",
    "print(\"Dataframe Dimension: {} Rows, {} Columns\".format(*df.shape))\n",
    "\n",
    "# Create New Variables: \n",
    "# Word Length\n",
    "df[\"Word Count\"] = df['Review Text'].str.split().apply(len)\n",
    "# Character Length\n",
    "df[\"Character Count\"] = df['Review Text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Character Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "      <td>22628.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.282880</td>\n",
       "      <td>4.183092</td>\n",
       "      <td>0.818764</td>\n",
       "      <td>2.631784</td>\n",
       "      <td>60.211950</td>\n",
       "      <td>308.761534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.328176</td>\n",
       "      <td>1.115911</td>\n",
       "      <td>0.385222</td>\n",
       "      <td>5.787520</td>\n",
       "      <td>28.533053</td>\n",
       "      <td>143.934126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>302.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>508.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age        Rating  Recommended IND  Positive Feedback Count  \\\n",
       "count  22628.000000  22628.000000     22628.000000             22628.000000   \n",
       "mean      43.282880      4.183092         0.818764                 2.631784   \n",
       "std       12.328176      1.115911         0.385222                 5.787520   \n",
       "min       18.000000      1.000000         0.000000                 0.000000   \n",
       "25%       34.000000      4.000000         1.000000                 0.000000   \n",
       "50%       41.000000      5.000000         1.000000                 1.000000   \n",
       "75%       52.000000      5.000000         1.000000                 3.000000   \n",
       "max       99.000000      5.000000         1.000000               122.000000   \n",
       "\n",
       "         Word Count  Character Count  \n",
       "count  22628.000000     22628.000000  \n",
       "mean      60.211950       308.761534  \n",
       "std       28.533053       143.934126  \n",
       "min        2.000000         9.000000  \n",
       "25%       36.000000       186.000000  \n",
       "50%       59.000000       302.000000  \n",
       "75%       88.000000       459.000000  \n",
       "max      115.000000       508.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describing al statistical values\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'normpdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-65387bb6a3e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#Add a fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormpdf\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mage_bin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage_bin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'normpdf'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create bin to store ages\n",
    "age_bin= np.arange(18, 100, 5)\n",
    "#Average age\n",
    "age_avg = np.average(df['Age'])\n",
    "#age standard devation\n",
    "age_std = np.std(df['Age'])\n",
    "\n",
    "#Create histogram\n",
    "plt.hist(df['Age'], bins = age_bin, alpha = 0.8, edgecolor='black', linewidth =1.5, color ='darkblue', density= 1)\n",
    "\n",
    "#Add a fit\n",
    "y = mpl.normpdf( age_bin, age_avg, age_std)\n",
    "l = plt.plot(age_bin, y, 'r--', linewidth=1)\n",
    "\n",
    "#Set x axis ticks to match bins\n",
    "plt.xticks(age_bin)\n",
    "\n",
    "#Add labels and title\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Age Probability Density\")\n",
    "plt.title(\"Age Distribution\")\n",
    "\n",
    "#Add average line\n",
    "plt.axvline(age_avg, color='green', linestyle = 'dashed', linewidth= 2)\n",
    "\n",
    "#Use grey background\n",
    "plt.style.use('bmh')\n",
    "\n",
    "#Display histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, the histogram is skewed to the right, there appears to be a normal distribution of the ages. The average age is somewhere around 40. The main demographic of the\n",
    "It is possible that some users are faking their age, in particular those aged 90+. They might be removed in cleaning the datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bin for rating\n",
    "rating_bin = np.arange(1, 6, 1)\n",
    "\n",
    "#Create histogram\n",
    "plt.hist(df['Rating'], bins = rating_bin, alpha = 0.8, edgecolor='black', linewidth =1.5, color ='darkblue', density= 1)\n",
    "\n",
    "#Add labels and title\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Rating Probability Density\")\n",
    "plt.title(\"Rating Distribution\")\n",
    "\n",
    "#Set x axis ticks to match bins\n",
    "plt.xticks(rating_bin)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram is clearly skewed to the left. The majority of reviews are positive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create wedges and corresponding labels for column in dataframe.\n",
    "def NameCount (df_in, column):\n",
    "    #Store unique entries \n",
    "    names = df_in[column].unique()\n",
    "    #remove nans\n",
    "    names = [x for x in names if str(x) != 'nan']\n",
    "    #Create array to store values\n",
    "    count = np.empty(len(names))\n",
    "    #Store recurrence of each value\n",
    "    for i in range(len(names)):\n",
    "        count[i] = df[(df[column] == names[i])].shape[0]\n",
    "    return names, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Division\n",
    "div_name, div_count = NameCount(df, 'Division Name')\n",
    "#Department \n",
    "dep_name, dep_count = NameCount(df, 'Department Name')\n",
    "#Class\n",
    "class_name, class_count = NameCount(df, 'Class Name')\n",
    "plt.pie(div_count, labels=div_name, autopct='%1.1f%%', shadow=True, radius= 1)\n",
    "plt.title(\"Division\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see from PIE chart 59.1% contains Genreal Division,\n",
    "                             6.3% contains Intimates divison and\n",
    "                            34.6%  contains General petite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(dep_count, labels=dep_name, autopct='%1.1f%%', shadow=True, radius= 1)\n",
    "plt.title(\"Department\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AS we can see from graph (1)16.2% Bottoms, (2.)27.2%Dresses, (3.)44.4% Tops, (4.)7.3%Intimate, (5.)0.5% Trend, (6.)4.4% Jackets in Department Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the text comment/ review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking random text such as Revies and Title\n",
    "pd.set_option('max_colwidth', 500)\n",
    "df[[\"Title\",\"Review Text\", \"Rating\"]].sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing wordcloud lib if not insatlled\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "#ps = LancasterStemmer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocessing(data):\n",
    "    txt = data.str.lower().str.cat(sep=' ') #1\n",
    "    words = tokenizer.tokenize(txt) #2\n",
    "    words = [w for w in words if not w in stop_words] #3\n",
    "    #words = [ps.stem(w) for w in words] #4\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "df[\"Review Text\"]= df[\"Review Text\"].astype(str)\n",
    "\n",
    "# Applying Model, Variable Creation\n",
    "df['Polarity Score']=df[\"Review Text\"].apply(lambda x:SIA.polarity_scores(x)['compound'])\n",
    "df['Neutral Score']=df[\"Review Text\"].apply(lambda x:SIA.polarity_scores(x)['neu'])\n",
    "df['Negative Score']=df[\"Review Text\"].apply(lambda x:SIA.polarity_scores(x)['neg'])\n",
    "df['Positive Score']=df[\"Review Text\"].apply(lambda x:SIA.polarity_scores(x)['pos'])\n",
    "\n",
    "# Converting 0 to 1 Decimal Score to a Categorical Variable\n",
    "df['Sentiment']=''\n",
    "df.loc[df['Polarity Score']>0,'Sentiment']='Positive'\n",
    "df.loc[df['Polarity Score']==0,'Sentiment']='Neutral'\n",
    "df.loc[df['Polarity Score']<0,'Sentiment']='Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentstandardize_barplot(x,y,hue, data, ax=None, order= None):\n",
    "    \"\"\"\n",
    "    Standardize by percentage the data using pandas functions, then plot using Seaborn.\n",
    "    Function arguments are and extention of Seaborns'.\n",
    "    \"\"\"\n",
    "    sns.barplot(x= x, y=y, hue=hue, ax=ax, order=order,\n",
    "    data=(data[[x, hue]]\n",
    "     .reset_index(drop=True)\n",
    "     .groupby([x])[hue]\n",
    "     .value_counts(normalize=True)\n",
    "     .rename('Percentage').mul(100)\n",
    "     .reset_index()\n",
    "     .sort_values(hue)))\n",
    "    plt.title(\"Percentage Frequency of {} by {}\".format(hue,x))\n",
    "    plt.ylabel(\"Percentage %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huevar = \"Recommended IND\"\n",
    "xvar = \"Sentiment\"\n",
    "f, axes = plt.subplots(1,2,figsize=(12,5))\n",
    "sns.countplot(x=xvar, hue=huevar,data=df, ax=axes[0], order=[\"Negative\",\"Neutral\",\"Positive\"])\n",
    "axes[0].set_title(\"Occurence of {}\\nby {}\".format(xvar, huevar))\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "percentstandardize_barplot(x=xvar,y=\"Percentage\", hue=huevar,data=df, ax=axes[1])\n",
    "axes[1].set_title(\"Percentage Normalized Occurence of {}\\nby {}\".format(xvar, huevar))\n",
    "axes[1].set_ylabel(\"% Percentage by {}\".format(huevar))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According to Graph:\n",
    "\n",
    "Nearly 80% sentiment are positive having Recommended IND as 1.\n",
    "\n",
    "Below 20% sentiment are positive having Recommended IND as 0.\n",
    "\n",
    "Below 60% sentiment are neutral having Recommended IND as 1.\n",
    "\n",
    "Nearly 50% sentiment are neutral having Recommended IND as 0.\n",
    "\n",
    "Above 30%  sentiment are negative having Recommended IND as 1.\n",
    "\n",
    "Above 60%  sentiment are negative having Recommended IND as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,2, figsize=[9,9])\n",
    "sns.countplot(x=\"Sentiment\", data=df, ax=axes[0,0], order=[\"Negative\",\"Neutral\",\"Positive\"])\n",
    "axes[0,0].set_xlabel(\"Sentiment\")\n",
    "axes[0,0].set_ylabel(\"Count\")\n",
    "axes[0,0].set_title(\"Overall Sentiment Occurrence\")\n",
    "\n",
    "sns.countplot(x=\"Rating\", data=df, ax=axes[0,1])\n",
    "axes[0,1].set_xlabel(\"Rating\")\n",
    "axes[0,1].set_ylabel(\"\")\n",
    "axes[0,1].set_title(\"Overall Raiting Occurrence\")\n",
    "\n",
    "percentstandardize_barplot(x=\"Rating\",y=\"Percentage\",hue=\"Sentiment\",data=df, ax=axes[1,0])\n",
    "axes[1,0].set_xlabel(\"Rating\")\n",
    "axes[1,0].set_ylabel(\"Percentage %\")\n",
    "axes[1,0].set_title(\"Standardized Percentage Raiting Frequency\\nby Sentiment\")\n",
    "\n",
    "percentstandardize_barplot(x=\"Sentiment\",y=\"Percentage\",hue=\"Rating\",data=df, ax=axes[1,1])\n",
    "axes[1,1].set_ylabel(\"Occurrence Frequency\")\n",
    "axes[1,1].set_title(\"Standardized Percentage Sentiment Frequency\\nby Raiting\")\n",
    "axes[1,1].set_xlabel(\"Sentiment\")\n",
    "axes[1,1].set_ylabel(\"\")\n",
    "\n",
    "f.suptitle(\"Distribution of Sentiment Score and Rating for Customer Reviews\", fontsize=14)\n",
    "f.tight_layout()\n",
    "f.subplots_adjust(top=0.92)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the Graph:\n",
    "\n",
    "1)More than 20,000 are positive sentiments. || (4) 12,000+ have rating of 5. ||(7)Very few neutral sentiments has a rating of 5 \n",
    "\n",
    "2)Less than 2500 are neagtive sentiments.   || (5) rarting of 4 ranges from 4,000 to 6,000.||(8)about 40% of Negative sentiments has a rarting of 1 \n",
    "\n",
    "3)very few Neutral  sentiments.             || (6)Nearly 100% of positive sentiments has rating 5.||(9)Nearly 60% positive sentiments tends to have 5 rating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10)Nearly 10% of Neutral sentiments tend to have 5 rating\n",
    "\n",
    "11)About 30% of Neutral sentiments tend to have 3 rating\n",
    "\n",
    "12)Less than 15% Negative sentiments tend to have 5 rating(in this case it is highest)\n",
    "\n",
    "13)less than 30% Negative sentiments tend to have 3 rating(in this case it is  highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweakable Variables (Note to Change Order Arguement if Xvar is changed)\n",
    "xvar = \"Sentiment\"\n",
    "huevar = \"Department Name\"\n",
    "rowvar = \"Recommended IND\"\n",
    "\n",
    "# Plot\n",
    "f, axes = plt.subplots(2,2,figsize=(10,10), sharex=False,sharey=False)\n",
    "for i,x in enumerate(set(df[rowvar][df[rowvar].notnull()])):\n",
    "    percentstandardize_barplot(x=xvar,y=\"Percentage\", hue=huevar,data=df[df[rowvar] == x],\n",
    "                 ax=axes[i,0], order=[\"Negative\",\"Neutral\",\"Positive\"])\n",
    "    percentstandardize_barplot(x=xvar,y=\"Percentage\", hue=\"Rating\",data=df[df[rowvar] == x],\n",
    "                 ax=axes[i,1], order=[\"Negative\",\"Neutral\",\"Positive\"])\n",
    "\n",
    "# Plot Aesthetics\n",
    "axes[1,0].legend_.remove()\n",
    "axes[1,1].legend_.remove()\n",
    "axes[0,1].set_ylabel(\"\")\n",
    "axes[1,1].set_ylabel(\"\")\n",
    "axes[0,0].set_xlabel(\"\")\n",
    "axes[0,1].set_xlabel(\"\")\n",
    "axes[0,0].set_ylabel(\"Recommended = FALSE\\nPercentage %\")\n",
    "axes[1,0].set_ylabel(\"Recommended = TRUE\\nPercentage %\")\n",
    "axes[1,1].set_title(\"\")\n",
    "\n",
    "# Common title and ylabel\n",
    "f.text(0.0, 0.5, 'Subplot Rows\\nSliced by Recommended', va='center', rotation='vertical', fontsize=12)\n",
    "f.suptitle(\"Review Sentiment by Department Name and Raiting\\nSubplot Rows Slice Data by Recommended\", fontsize=16)\n",
    "f.tight_layout()\n",
    "f.subplots_adjust(top=0.93)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According to Graph:\n",
    "\n",
    "1)Positive Sentiments:more than 40% recommendations are for tops And about 30% for Dresses\n",
    "\n",
    "2)Negative Sentiments:more than 40% recommendations are for tops And less than 30% for Dresses\n",
    "\n",
    "3)Neutral Sentiments:more than 40% recommendations are for tops And less than  30% for Dresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)Positive Sentiments:more than 40% recommnedation has a rating of 3\n",
    "\n",
    "5)Negative Sentiments:about 35% recommnedation has a rating of 3\n",
    "\n",
    "6)Neutral  Sentiments:about 35% recommnedation has a rating of 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Positivity Score by Positive Feedback Count\n",
    "ax = sns.jointplot(x= df[\"Positive Feedback Count\"], y=df[\"Positive Score\"], kind='reg', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df['Class Name'].value_counts()\n",
    "df1=df['Rating'].value_counts().to_frame()\n",
    "avgdf1 = df.groupby('Class Name').agg({'Rating': np.average})\n",
    "\n",
    "trace = go.Scatter3d( x = avgdf1.index,\n",
    "                      y = avgdf1['Rating'],\n",
    "                      z = cv[avgdf1.index],\n",
    "                      mode = 'markers',\n",
    "                      marker = dict(size=10,color=avgdf1['Rating']),\n",
    "                      hoverinfo =\"text\",\n",
    "                      text=\"Class: \"+avgdf1.index+\" \\ Average Rating: \"+avgdf1['Rating'].map(' {:,.2f}'.format).apply(str)+\" \\ Number of Reviewers: \"+cv[avgdf1.index].apply(str)\n",
    "                      )\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(title=\"Average Rating & Class & Number of Reviewers\",\n",
    "                   scene = dict(\n",
    "                    xaxis = dict(title='Class'),\n",
    "                    yaxis = dict(title='Average Rating'),\n",
    "                    zaxis = dict(title='Number of Sales'),),\n",
    "                   margin = dict(l=30, r=30, b=30, t=30))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n",
    "plt.savefig('3D_Scatter.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According to this 3D Graph:\n",
    "\n",
    "1.class Dresses has an avg rating of 4.14 and reviewed by 6000+ people.\n",
    "\n",
    "2.class Knits has an avg rating of 4.15 and reviewed by 4000+ people.\n",
    "\n",
    "3.class Blouses has an avg rating of 4.14 and reviewed by 2983 people.\n",
    "\n",
    "4.class Jeans has an avg rating of 4.35 and reviewed by 1104 people.\n",
    "\n",
    "5.class Trends has an avg rating of 3.84 and reviewed by 118 people.\n",
    "\n",
    "6.class pants has an avg rating of 4.26 and reviewed by 1300+ people.\n",
    "\n",
    "ETC...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the ratings into 2 classes\n",
    "Class: Bad when Rating <=3\n",
    "Class: Good otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class\"] = \"Bad\"\n",
    "df.loc[df.Rating >= 3,[\"Class\"]] = \"Good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns[df.isna().any()].tolist():\n",
    "    print(i,'has',df[df[i].isna()==True].shape[0],'Null Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret(rating):\n",
    "    if rating>3:\n",
    "        return 'Good'\n",
    "    else:\n",
    "        return 'Bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Womens_Clothing_E_Commerce_Reviews.csv\")\n",
    "df['Review Text']=df['Review Text'].astype(str)\n",
    "df['Review Length']=df['Review Text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_N = 100\n",
    "#convert list of list into text\n",
    "#a=''.join(str(r) for v in df_usa['title'] for r in v)\n",
    "\n",
    "a = df['Review Text'].str.lower().str.cat(sep=' ')\n",
    "\n",
    "# removes punctuation,numbers and returns list of words\n",
    "b = re.sub('[^A-Za-z]+', ' ', a)\n",
    "\n",
    "#remove all the stopwords from the text\n",
    "stop_words = list(get_stop_words('en'))         \n",
    "nltk_words = list(stopwords.words('english'))   \n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "word_tokens = word_tokenize(b)\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "filtered_sentence = []\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "# Remove characters which have length less than 2  \n",
    "without_single_chr = [word for word in filtered_sentence if len(word) > 2]\n",
    "\n",
    "# Remove numbers\n",
    "cleaned_data_title = [word for word in without_single_chr if not word.isnumeric()]        \n",
    "\n",
    "# Calculate frequency distribution\n",
    "word_dist = nltk.FreqDist(cleaned_data_title)\n",
    "rslt = pd.DataFrame(word_dist.most_common(top_N),\n",
    "                    columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class\"] = \"Bad\"\n",
    "df.loc[df.Rating > 3,[\"Class\"]] = \"Good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(axis=0,how='any')\n",
    "rating_class = df[(df['Rating'] >3) | (df['Rating']<=3)]\n",
    "X_review=rating_class['Review Text']\n",
    "y=rating_class['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def text_process(review):\n",
    "    nopunc=[word for word in review if word not in string.punctuation]\n",
    "    nopunc=''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_transformer=CountVectorizer(analyzer=text_process).fit(X_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_review = bow_transformer.transform(X_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, predict))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Good review example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_positive=df['Review Text'][3]\n",
    "rating_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "rating_positive_transformed = bow_transformer.transform([rating_positive])\n",
    "nb.predict(rating_positive_transformed)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual\n",
    "df['Class'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bad review example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_negative=df['Review Text'][61]\n",
    "rating_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "rating_negative_transformed = bow_transformer.transform([rating_negative])\n",
    "nb.predict(rating_negative_transformed)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual\n",
    "df['Class'][61]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randaom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_random=df['Review Text'][43]\n",
    "rating_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "rating_random_transformed = bow_transformer.transform([rating_negative])\n",
    "nb.predict(rating_random_transformed)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual\n",
    "df['Class'][43]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm used and why:\n",
    " \n",
    "We have used naive bayes classifier as it is a classification technique based on Bayes Theorem with an assumption of independence among predictors. Naive Bayes model is easy to build and particularly useful for very large datasets. Along with simplicity, Naive Bayes is known to outperform even the most-sophisticated classification methods. It proves to be quite robust to irrelevant features, which it ignores. It learns and predicts very fast and it does not require lots of storage. So, why is it then called naive? The naive was added to the account for one assumption that is required for Bayes to work optimally: all features must be independent of each other. In reality, this is usually not the case; however, it still returns very good accuracy in practice even when the independent assumption does not hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification/ Spam Filtering/ Sentiment Analysis: Naive Bayes classifiers are mostly used in text classification (due to their better results in multi-class problems and independence rule) have a higher success rate as compared to other algorithms. As a result, it is widely used in Spam filtering (identify spam e-mail) and Sentiment Analysis (in social media analysis, to identify positive and negative customer sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also used multivariate method for data analysis\n",
    "Multivariate analysis provides a more accurate view of the behavior between variables that are highly correlated, and can detect potential problems in a product or process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Advantages:\n",
    "\n",
    "It is easy to apply and predicts the class of test data set fast. It also performs well in multi-class prediction\n",
    "When the assumption of independence holds, a Naive Bayes classifier performs better compared to the other models like logistic regression as you need less training data.\n",
    "It performs well in the case of categorical input variables compared to a numerical variable(s). For the numerical variable, a normal distribution is assumed (bell curve, which is a strong assumption)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have achieved the desired model with 88% accuracy which predicts the Rating class.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
